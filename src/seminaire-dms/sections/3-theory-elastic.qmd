## Adresses √† retrouver dans Ga√Øa

*Exemple d'adresses √† retrouver :*  

| **Adresse √† retrouver** | **COG** | **Code Postal** | **Libell√© commune** |
|-------------------------|---------|-----------------|---------------------|
| 131, rue du fbg Bannier |         | 45000           | Orl√©ans             |
| 0033 ave J. Jaur√®s    | 92040   |            |              |

Adresses dans Ga√Øa :  

| **Adresse** | **COG** |
|-------------|---------|
| 131 rue du faubourg bannier | 45234 |
| 33 avenue jean jaures | 92040 |

C'est pourquoi il faut un moteur de recherche ‚öôÔ∏è.

## Un moteur de recherche ‚öôÔ∏è

- Google : recherche par mot cl√©.  
- Pour la recherche d'adresse :  
  - Google Maps.
  - Addok, moteur de recherche de la BAN.

## ElasticSearch 

- Cr√©√© en 2010 par Shay Bannon.  
- Moteur ‚öôÔ∏è utilisable en n'importe quel langage (requ√™tes HTTP).  
- Faire des recherches rapides sur tout type de donn√©es (textes, objets g√©om√©triques...).  


## C'est quoi concr√®tement ElasticSearch ?

- [**ElasticSearch**]{.blue2} : logiciel pour l'indexation et la recherche de donn√©es.

- Utilisation en pratique avec [**Python**]{.green2} : packages *elasticsearch* et *elasticsearch-dsl*.


## Pourquoi ElasticSearch pour la recherche textuelle ?

| **Crit√®res**                         | **ElasticSearch** | **SQL** | **Addok**|
|:-------------------------------------|:-----------------:|:-------:|:-------:|
| Recherche de texte avanc√©e           | ‚úÖ | ‚ùå | ‚úÖ |
| Personnalisation des recherches      | ‚úÖ | ‚ùå | ‚ùå |
| Rapidit√©                             | ‚úÖ | ‚úÖ | ‚úÖ |
| Pr√©cision                            | ‚úÖ | ‚ùå | ‚ö†Ô∏è |
| Facilit√© d'impl√©mentation            | ‚ùå | ‚úÖ | ‚úÖ |
| Maintenance                          | ‚ö†Ô∏è | ‚úÖ | ‚ùå |

::: {.notes}
Donner explication addok
::: 

<!-- a refaire car je ne connais pas addok, j'ai pas compris -->

<!-- | **Crit√®res**                     | **Elasticsearch (Avantages)**                                                                                             | **SQL (Inconv√©nients)**                                                                                       |
|----------------------------------|----------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------|
| **Recherche de texte avanc√©e**   | Con√ßu pour la recherche full-text avec tol√©rance aux fautes d'orthographe (fuzzy search, correspondance partielle)         | Requ√™tes full-text limit√©es et moins adapt√©es aux variations d'orthographe                                    |
| **Performances**                 | Optimis√© pour les recherches intensives sur de gros volumes de texte                                                       | Moins performant pour des recherches complexes ou de grandes quantit√©s de donn√©es textuelles                  |
| **Personnalisation des scores**  | Permet de pond√©rer et personnaliser les scores des r√©sultats pour une meilleure pertinence                                | Les options de personnalisation des scores sont limit√©es                                                      |
| **Scalabilit√©**                  | Distribution facile sur plusieurs n≈ìuds pour g√©rer de grands ensembles de donn√©es                                         | Scalabilit√© plus complexe et generalement moins performante pour des recherches intensives                    |
| **Flexibilit√© des requ√™tes**     | Recherches avanc√©es comme les synonymes, phon√©tique, et suggestions automatiques                                          | Requ√™tes avanc√©es limit√©es, difficile √† impl√©menter en SQL                                                    |
| **Complexit√© d'impl√©mentation**  | Peut √™tre complexe √† mettre en ≈ìuvre pour des √©quipes non famili√®res avec l'outil                                         | Plus simple et souvent mieux ma√Ætris√© par les √©quipes                                                        |
| **Consommation des ressources**  | Consomme plus de m√©moire et de CPU, en particulier pour l'indexation initiale                                             | Consommation de ressources generalement inf√©rieure pour des requ√™tes simples                                  |
| **Co√ªt de stockage**             | Peut impliquer une duplication des donn√©es (co√ªt suppl√©mentaire de stockage)                                              | Pas de duplication n√©cessaire                                                                                 | -->

<!-- ## Outils pour moteur ElasticSearch

- [**Mappings**]{.blue2} üè∑Ô∏è : sp√©cifier les traitements √† appliquer pour chaque variable de nos donn√©es.  
  - *Variable_a ‚Üí Analyzer_for_numbers*  
  - *Variable_b ‚Üí Analyzer_for_address_text*  
  - *Variable_c ‚Üí Analyzer_for_address_text*  
- [**Settings**]{.blue2} üõ†Ô∏è : d√©finir les diff√©rents traitements.  
  - *Analyzer_for_numbers ‚Üí Filtre_Œ±, Filtre_Œ≤ + Tokenizer_1*  
  - *Analyzer_for_address_text ‚Üí Filtre_Œ≥, Filtre_Œ¥, Filtre_Œµ + Tokenizer_2*  
- [**Requ√™tes**]{.blue2} üîç : recherche sur les variables d√©finies dans les mappings.  

::: {.notes}
Et √©ventuellement, savoir coder en Python/Java...
::: 

On peut commencer √† cr√©er notre moteur ‚öôÔ∏è. -->

# √âtape 1 : pouvoir comparer l'adresse recherch√©e avec les donn√©es Ga√Øa.

## Filtres

<!-- - D√©finis dans les *settings* üõ†Ô∏è.   -->
- Normalisent les donn√©es.  
- Pour les donn√©es du r√©f√©rentiel et pour les adresses recherch√©es.

## Filtres impl√©ment√©s

- Lowercase  
- Asciifolding  
- Ponctuation  
- S√©paration des nombres et lettres *(ex : 14bis ‚Üí 14 bis)*  
- Suppression des espaces suppl√©mentaires  
- [**Prise en compte des synonymes**]{.red2}  *(ex : ave = avenue, st = saint)*  

# √âtape 2 : d√©finir un score pour √©valuer la pertinence.

## Base de donn√©es classique

*Exemple*  

| idVoie | nom de voie             |
|---|:-----------------------------|
| A | du general leclerc           |
| B | du general charles de gaulle |
| C | du point du jour             |
| D | verdier                      |
| E | des cours                    |

## Recherche par mot

- [**Pour chaque nom de voie du r√©f√©rentiel**]{.blue2}, compter le nombre de mots qui matchent üéØ avec les mots de l'adresse recherch√©e.  
- Recherche par groupes de caract√®res √©galement possible, abord√©e dans la suite.   

## Score avec tokenizer "mot"

[**Tokenizer**]{.green2} = fa√ßon de d√©couper le texte recherch√© et cibl√©.  

<br>

[**Pour retourner la voie la plus pertinente**]{.blue2}, on construit un score pour chaque voie :
$$
score_{voie} = \sum_{\text{‚àÄt} \in \text{T}} {nb\_occurrence}_t
$$

t = token  
T = ensemble des tokens de l'adresse recherch√©e  

## Score avec tokenizer "mot"

*Exemple : score avec tokenizer "mot" de "88 avenue du general charles de gaulle"*

| idVoie | nom de voie             | score |
|---|:-----------------------------|-------|
| A | **du general** leclerc           | 2     |
| B | **du general charles de gaulle** | 5     |
| C | **du** point **du** jour         | 2     |
| D | verdier                          | 0     |
| E | des cours                        | 0     |

[**Dans une grande base de donn√©es, c'est extr√™mement long.**]{.red2}

# √âtape 3 : utiliser un index invers√©. Mais qu'est ce donc ?

## Index invers√© mot

*Exemple*  

<!-- | idVoie | nom de voie             |                        | mot     | occurrences              |
|---|:-----------------------------|                        |-----------|--------------------------|
| A | du general leclerc           |                        | general   | {"A": 1, "B": 1}         |
| B | du general charles de gaulle |        devient         | jour      | {"C": 1}                 |
| C | du point du jour             |                        | du        | {"A": 1, "B": 1, "C": 2} |
| D | verdier                      |                        | ...       | ...                      |
| E | des cours                    | -->

<div style="display: flex; justify-content: space-between;">

<table>
  <thead>
    <tr>
      <th>idVoie</th>
      <th>nom de voie</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>A</td>
      <td>du general leclerc</td>
    </tr>
    <tr>
      <td>B</td>
      <td>du general charles de gaulle</td>
    </tr>
    <tr>
      <td>C</td>
      <td>du point du jour</td>
    </tr>
    <tr>
      <td>D</td>
      <td>verdier</td>
    </tr>
    <tr>
      <td>E</td>
      <td>des cours</td>
    </tr>
  </tbody>
</table>

<!-- Ajoutez un espacement entre les deux tableaux -->
<div style="margin-left: 130px;"></div>

<table>
  <thead>
    <tr>
      <th>mot</th>
      <th>occurrences</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>general</td>
      <td>{"A": 1, "B": 1}</td>
    </tr>
    <tr>
      <td>jour</td>
      <td>{"C": 1}</td>
    </tr>
    <tr>
      <td>du</td>
      <td>{"A": 1, "B": 1, "C": 2}</td>
    </tr>
    <tr>
      <td>cours</td>
      <td>{"E": 1}</td>
    </tr>
    <tr>
      <td>...</td>
      <td>...</td>
    </tr>
  </tbody>
</table>
</div>

[**Comptage direct ‚ö° des occurrences**]{.green2} de chaque mot de la base par idVoie.

::: {.notes}
- Faire un index invers√© par mot, c'est r√©cup√©rer tous les mots des noms de voie dans le r√©f√©rentiel et on les aplati dans une colonne.  
- Il y a autant de lignes qu'il y a de mots diff√©rents dans les noms de voie du r√©f√©rentiel. Les mots les plus fr√©quents seront ceux qui ont le plus d'occurences.  
- Nous obtenons directement le comptage de chaque mot par idVoie, pour tous les mots pr√©sents dans les noms de voie du r√©f√©rentiel.  
- L'index invers√© est fait en amont des requetes.  
::: 

# √âtape 4 : prendre en compte les variations textuelles.

## Recherche par n-grams de caract√®res

[**Contourner les fautes d'orthographes**]{.blue2} : chaque mot est d√©coup√© en sous-cha√Ænes de n caract√®res cons√©cutifs.  

*Exemple de d√©coupage en 3-grams de caract√®res du texte "avenue verdier" :*  
**ave, ven, enu, nue, ver, erd, rdi, die, ier**

<!-- | token    | 3-grams                 |
|----------|-------------------------|
| avenue   | ave, ven, enu, nue      |
| verdier  | ver, erd, rdi, die, ier | -->


## Index invers√© 3-grams

*Exemple*  

<!-- | 3-grams | occurrences           |
|---------|-----------------------|
| gen     | {"A": 1, "B": 1}      |
| char    | {"B": 1}              |
| our     | {"C": 1, "E": 1}      |
| ...     | ...                   | -->



<div style="display: flex; justify-content: space-between;">

<table>
  <thead>
    <tr>
      <th>idVoie</th>
      <th>nom de voie</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>A</td>
      <td>du general leclerc</td>
    </tr>
    <tr>
      <td>B</td>
      <td>du general charles de gaulle</td>
    </tr>
    <tr>
      <td>C</td>
      <td>du point du jour</td>
    </tr>
    <tr>
      <td>D</td>
      <td>verdier</td>
    </tr>
    <tr>
      <td>E</td>
      <td>des cours</td>
    </tr>
  </tbody>
</table>

<!-- Ajoutez un espacement entre les deux tableaux -->
<div style="margin-left: 130px;"></div>

<table>
  <thead>
    <tr>
      <th>3-gram</th>
      <th>occurrences</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>gen</td>
      <td>{"A": 1, "B": 1}</td>
    </tr>
    <tr>
      <td>char</td>
      <td>{"B": 1}</td>
    </tr>
    <tr>
      <td>our</td>
      <td>{"C": 1, "E": 1}</td>
    </tr>
    <tr>
      <td>oin</td>
      <td>{"C": 1}</td>
    </tr>
    <tr>
      <td>...</td>
      <td>...</td>
    </tr>
  </tbody>
</table>
</div>

::: {.notes}
- Il y a autant de lignes qu'il ya de trigrams diff√©rents dans les noms de voie du r√©f√©rentiel.  
- Si un mot est inf√©rieur √† la taille n=3, il ne sera pas pris en compte. Par exemple : du g√©n√©ral de gaules, "du" et "de" n‚Äôappara√Ætront pas dans l'index et donc ne seront pas pris en compte dans les matchs trigrams.  
:::

## Score avec tokenizer "n-grams"

Score pour chaque voie :
$$
score_{voie} = \sum_{\text{‚àÄngram} \in \text{N}} {nb\_occurrence}_{ngram}
$$

N = ensemble des n-grams de l'adresse recherch√©e

## Limites des n-grams

$$
\downarrow \text{taille n-grams}
\Rightarrow \text{taille index invers√©} \uparrow 
\Rightarrow \text{temps de recherche} \uparrow
$$

- Limitation √† n‚àà{3,4,5} pour notre cas.  
- Tests effectu√©s pour choisir ces valeurs, en fonction de [**la pr√©cision et la rapidit√©**]{.blue2} des requ√™tes.  

## Fuzziness

Contourner les fautes d'orthographes d'une autre fa√ßon : [**fuzziness**]{.green2}.  

<br>

Pour matcher üéØ deux mots avec une fuzziness de niveau 1 = corriger l'un des mots :

- Ajout d'une lettre.  
- Suppression d'une lettre.  
- Remplacement d'une lettre.  
- √âchanger deux lettres de place.  

## Score global 

Le score global va donc combiner la somme des matchs üéØ au niveau :

- mot.  
- n-grams.  
- fuzziness.  

## Boost

- On peut donner plus ou moins d'importance aux diff√©rents matchs üéØ.  
- Chaque occurrence est multipli√©e par un facteur, appel√© [**boost**]{.blue2}, qui d√©pend du niveau de match üéØ.  

## Retour sur le score global

$$
score_{voie} = \sum_{\text{‚àÄn} \in \text{N}} \sum_{\text{‚àÄsc} \in \text{n}} boost_{n}*{nb\_occurrence}_{sc}
$$

N = ensemble des niveaux *(niveau mot, niveau fuzzi...)*  
n = niveau  
sc = sous-cha√Æne *(un mot, un 3-grams...)*  

<!-- ## Configurer le moteur ‚öôÔ∏è

Une fois qu'on a la th√©orie, il faut l'appliquer en pratique.  

Le package elasticsearch permet d'indexer les donn√©es en fournissant :  

- Un dataframe üìã des donn√©es du r√©f√©rentiel Ga√Øa.  
- Des [**settings**]{.blue2} üõ†Ô∏è o√π on d√©finit nos diff√©rents **analyzers**, englobant les filtres et le motizer.  
- Des [**mappings**]{.green2} üè∑Ô∏è o√π pour chaque **variable**, on fournit un analyzer.   -->

## Faire des recherches

Une recherche = une requ√™te üîç.  

*Requ√™te pour retrouver la voie :*  

- Match üéØ nom de voie entier sans d√©coupage avec fuzzi 1 ‚Üí boost 200. *Ex : "3 rue du genral de gaulle" avec "du gen**e**ral de gaulle"*.  
- Match üéØ chaque mot du nom de voie avec fuzzi 1 ‚Üí boost 15. *Ex : "3 rue du genral de gaule" avec "du", "gen**e**ral", "de", "gaul**l**e"*.  
- Match üéØ chaque mot du type de voie avec fuzzi 1 ‚Üí boost 5. *Ex : "3 rue du general de gaule" avec "rue"*.  
- Match üéØ chaque 3 √† 5-grams du nom de voie ‚Üí boost 1.  

√Ä chaque fois qu'une sous-cha√Æne valide l'une de ces conditions, le score va ‚á° en fonction du boost associ√©.

::: {.notes}
- On match √† chaque 3-grams, exemple avec verdier.  
- Les ngrams c'est notre dernier recours, on va retourner comme voie plus pertinente les match sur nom de voie complet et sur token mais ngrams c'est notre roue de secours.
:::