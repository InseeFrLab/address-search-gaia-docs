## Adresses Ã  retrouver dans GaÃ¯a

*Exemple d'adresses Ã  retrouver :*  

| **Adresse Ã  retrouver** | **COG** | **Code Postal** | **LibellÃ© commune** |
|-------------------------|---------|-----------------|---------------------|
| 131, rue du fbg Bannier |         | 45000           | OrlÃ©ans             |
| 0033 ave J. JaurÃ¨s    | 92040   |            |              |

Adresses dans GaÃ¯a :  

| **Adresse** | **COG** |
|-------------|---------|
| 131 rue du faubourg bannier | 45234 |
| 33 avenue jean jaures | 92040 |

C'est pourquoi il faut un moteur de recherche âš™ï¸.

## Un moteur de recherche âš™ï¸

- Google : recherche par mot clÃ©.  
- Pour la recherche d'adresse :  
  - Google Maps.
  - Addok, moteur de recherche de la BAN.

## ElasticSearch 

- CrÃ©Ã© en 2010 par Shay Bannon.  
- Moteur âš™ï¸ utilisable en n'importe quel langage (requÃªtes HTTP).  
- Faire des recherches rapides sur tout type de donnÃ©es (textes, objets gÃ©omÃ©triques...).  


## C'est quoi concrÃ¨tement ElasticSearch ?

- [**ElasticSearch**]{.blue2} : logiciel pour l'indexation et la recherche de donnÃ©es.

- Utilisation en pratique avec [**Python**]{.green2} : packages *elasticsearch* et *elasticsearch-dsl*.


## Pourquoi ElasticSearch pour la recherche textuelle ?

| **CritÃ¨res**                         | **ElasticSearch** | **SQL** | **Addok**|
|:-------------------------------------|:-----------------:|:-------:|:-------:|
| Recherche de texte avancÃ©e           | âœ… | âŒ | âœ… |
| Personnalisation des recherches      | âœ… | âŒ | âŒ |
| RapiditÃ©                             | âœ… | âœ… | âœ… |
| PrÃ©cision                            | âœ… | âŒ | âš ï¸ |
| FacilitÃ© d'implÃ©mentation            | âŒ | âœ… | âœ… |
| Maintenance                          | âš ï¸ | âœ… | âŒ |

::: {.notes}
Donner explication addok
::: 

<!-- a refaire car je ne connais pas addok, j'ai pas compris -->

<!-- | **CritÃ¨res**                     | **Elasticsearch (Avantages)**                                                                                             | **SQL (InconvÃ©nients)**                                                                                       |
|----------------------------------|----------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------|
| **Recherche de texte avancÃ©e**   | ConÃ§u pour la recherche full-text avec tolÃ©rance aux fautes d'orthographe (fuzzy search, correspondance partielle)         | RequÃªtes full-text limitÃ©es et moins adaptÃ©es aux variations d'orthographe                                    |
| **Performances**                 | OptimisÃ© pour les recherches intensives sur de gros volumes de texte                                                       | Moins performant pour des recherches complexes ou de grandes quantitÃ©s de donnÃ©es textuelles                  |
| **Personnalisation des scores**  | Permet de pondÃ©rer et personnaliser les scores des rÃ©sultats pour une meilleure pertinence                                | Les options de personnalisation des scores sont limitÃ©es                                                      |
| **ScalabilitÃ©**                  | Distribution facile sur plusieurs nÅ“uds pour gÃ©rer de grands ensembles de donnÃ©es                                         | ScalabilitÃ© plus complexe et generalement moins performante pour des recherches intensives                    |
| **FlexibilitÃ© des requÃªtes**     | Recherches avancÃ©es comme les synonymes, phonÃ©tique, et suggestions automatiques                                          | RequÃªtes avancÃ©es limitÃ©es, difficile Ã  implÃ©menter en SQL                                                    |
| **ComplexitÃ© d'implÃ©mentation**  | Peut Ãªtre complexe Ã  mettre en Å“uvre pour des Ã©quipes non familiÃ¨res avec l'outil                                         | Plus simple et souvent mieux maÃ®trisÃ© par les Ã©quipes                                                        |
| **Consommation des ressources**  | Consomme plus de mÃ©moire et de CPU, en particulier pour l'indexation initiale                                             | Consommation de ressources generalement infÃ©rieure pour des requÃªtes simples                                  |
| **CoÃ»t de stockage**             | Peut impliquer une duplication des donnÃ©es (coÃ»t supplÃ©mentaire de stockage)                                              | Pas de duplication nÃ©cessaire                                                                                 | -->

<!-- ## Outils pour moteur ElasticSearch

- [**Mappings**]{.blue2} ğŸ·ï¸ : spÃ©cifier les traitements Ã  appliquer pour chaque variable de nos donnÃ©es.  
  - *Variable_a â†’ Analyzer_for_numbers*  
  - *Variable_b â†’ Analyzer_for_address_text*  
  - *Variable_c â†’ Analyzer_for_address_text*  
- [**Settings**]{.blue2} ğŸ› ï¸ : dÃ©finir les diffÃ©rents traitements.  
  - *Analyzer_for_numbers â†’ Filtre_Î±, Filtre_Î² + Tokenizer_1*  
  - *Analyzer_for_address_text â†’ Filtre_Î³, Filtre_Î´, Filtre_Îµ + Tokenizer_2*  
- [**RequÃªtes**]{.blue2} ğŸ” : recherche sur les variables dÃ©finies dans les mappings.  

::: {.notes}
Et Ã©ventuellement, savoir coder en Python/Java...
::: 

On peut commencer Ã  crÃ©er notre moteur âš™ï¸. -->

# Ã‰tape 1 : pouvoir comparer l'adresse recherchÃ©e avec les donnÃ©es GaÃ¯a.

## Filtres

<!-- - DÃ©finis dans les *settings* ğŸ› ï¸.   -->
- Normalisent les donnÃ©es.  
- Pour les donnÃ©es du rÃ©fÃ©rentiel et pour les adresses recherchÃ©es.

## Filtres implÃ©mentÃ©s

- Lowercase  
- Asciifolding  
- Ponctuation  
- SÃ©paration des nombres et lettres *(ex : 14bis â†’ 14 bis)*  
- Suppression des espaces supplÃ©mentaires  
- [**Prise en compte des synonymes**]{.red2}  *(ex : ave = avenue, st = saint)*  

# Ã‰tape 2 : dÃ©finir un score pour Ã©valuer la pertinence.

## Base de donnÃ©es classique

*Exemple*  

| idVoie | nom de voie             |
|---|:-----------------------------|
| A | du general leclerc           |
| B | du general charles de gaulle |
| C | du point du jour             |
| D | verdier                      |
| E | des cours                    |

## Recherche par mot

- [**Pour chaque nom de voie du rÃ©fÃ©rentiel**]{.blue2}, compter le nombre de mots qui matchent ğŸ¯ avec les mots de l'adresse recherchÃ©e.  
- Recherche par groupes de caractÃ¨res Ã©galement possible, abordÃ©e dans la suite.   

## Score avec tokenizer "mot"

[**Tokenizer**]{.green2} = faÃ§on de dÃ©couper le texte recherchÃ© et ciblÃ©.  

<br>

[**Pour retourner la voie la plus pertinente**]{.blue2}, on construit un score pour chaque voie :
$$
score_{voie} = \sum_{\text{âˆ€t} \in \text{T}} {nb\_occurrence}_t
$$

t = token  
T = ensemble des tokens de l'adresse recherchÃ©e  

## Score avec tokenizer "mot"

*Exemple : score avec tokenizer "mot" de "88 avenue du general charles de gaulle"*

| idVoie | nom de voie             | score |
|---|:-----------------------------|-------|
| A | **du general** leclerc           | 2     |
| B | **du general charles de gaulle** | 5     |
| C | **du** point **du** jour         | 2     |
| D | verdier                          | 0     |
| E | des cours                        | 0     |

[**Dans une grande base de donnÃ©es, c'est extrÃªmement long.**]{.red2}

# Ã‰tape 3 : utiliser un index inversÃ©. Mais qu'est ce donc ?

## Index inversÃ© mot

*Exemple*  

<!-- | idVoie | nom de voie             |                        | mot     | occurrences              |
|---|:-----------------------------|                        |-----------|--------------------------|
| A | du general leclerc           |                        | general   | {"A": 1, "B": 1}         |
| B | du general charles de gaulle |        devient         | jour      | {"C": 1}                 |
| C | du point du jour             |                        | du        | {"A": 1, "B": 1, "C": 2} |
| D | verdier                      |                        | ...       | ...                      |
| E | des cours                    | -->

<div style="display: flex; justify-content: space-between;">

<table>
  <thead>
    <tr>
      <th>idVoie</th>
      <th>nom de voie</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>A</td>
      <td>du general leclerc</td>
    </tr>
    <tr>
      <td>B</td>
      <td>du general charles de gaulle</td>
    </tr>
    <tr>
      <td>C</td>
      <td>du point du jour</td>
    </tr>
    <tr>
      <td>D</td>
      <td>verdier</td>
    </tr>
    <tr>
      <td>E</td>
      <td>des cours</td>
    </tr>
  </tbody>
</table>

<!-- Ajoutez un espacement entre les deux tableaux -->
<div style="margin-left: 130px;"></div>

<table>
  <thead>
    <tr>
      <th>mot</th>
      <th>occurrences</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>general</td>
      <td>{"A": 1, "B": 1}</td>
    </tr>
    <tr>
      <td>jour</td>
      <td>{"C": 1}</td>
    </tr>
    <tr>
      <td>du</td>
      <td>{"A": 1, "B": 1, "C": 2}</td>
    </tr>
    <tr>
      <td>cours</td>
      <td>{"E": 1}</td>
    </tr>
    <tr>
      <td>...</td>
      <td>...</td>
    </tr>
  </tbody>
</table>
</div>

[**Comptage direct âš¡ des occurrences**]{.green2} de chaque mot de la base par idVoie.

::: {.notes}
- Faire un index inversÃ© par mot, c'est rÃ©cupÃ©rer tous les mots des noms de voie dans le rÃ©fÃ©rentiel et on les aplati dans une colonne.  
- Il y a autant de lignes qu'il y a de mots diffÃ©rents dans les noms de voie du rÃ©fÃ©rentiel. Les mots les plus frÃ©quents seront ceux qui ont le plus d'occurences.  
- Nous obtenons directement le comptage de chaque mot par idVoie, pour tous les mots prÃ©sents dans les noms de voie du rÃ©fÃ©rentiel.  
- L'index inversÃ© est fait en amont des requetes.  
::: 

# Ã‰tape 4 : prendre en compte les variations textuelles.

## Recherche par n-grams de caractÃ¨res

[**Contourner les fautes d'orthographes**]{.blue2} : chaque mot est dÃ©coupÃ© en sous-chaÃ®nes de n caractÃ¨res consÃ©cutifs.  

*Exemple de dÃ©coupage en 3-grams de caractÃ¨res du texte "avenue verdier" :*  
**ave, ven, enu, nue, ver, erd, rdi, die, ier**

<!-- | token    | 3-grams                 |
|----------|-------------------------|
| avenue   | ave, ven, enu, nue      |
| verdier  | ver, erd, rdi, die, ier | -->


## Index inversÃ© 3-grams

*Exemple*  

<!-- | 3-grams | occurrences           |
|---------|-----------------------|
| gen     | {"A": 1, "B": 1}      |
| char    | {"B": 1}              |
| our     | {"C": 1, "E": 1}      |
| ...     | ...                   | -->



<div style="display: flex; justify-content: space-between;">

<table>
  <thead>
    <tr>
      <th>idVoie</th>
      <th>nom de voie</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>A</td>
      <td>du general leclerc</td>
    </tr>
    <tr>
      <td>B</td>
      <td>du general charles de gaulle</td>
    </tr>
    <tr>
      <td>C</td>
      <td>du point du jour</td>
    </tr>
    <tr>
      <td>D</td>
      <td>verdier</td>
    </tr>
    <tr>
      <td>E</td>
      <td>des cours</td>
    </tr>
  </tbody>
</table>

<!-- Ajoutez un espacement entre les deux tableaux -->
<div style="margin-left: 130px;"></div>

<table>
  <thead>
    <tr>
      <th>3-gram</th>
      <th>occurrences</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>gen</td>
      <td>{"A": 1, "B": 1}</td>
    </tr>
    <tr>
      <td>char</td>
      <td>{"B": 1}</td>
    </tr>
    <tr>
      <td>our</td>
      <td>{"C": 1, "E": 1}</td>
    </tr>
    <tr>
      <td>oin</td>
      <td>{"C": 1}</td>
    </tr>
    <tr>
      <td>...</td>
      <td>...</td>
    </tr>
  </tbody>
</table>
</div>

::: {.notes}
- Il y a autant de lignes qu'il ya de trigrams diffÃ©rents dans les noms de voie du rÃ©fÃ©rentiel.  
- Si un mot est infÃ©rieur Ã  la taille n=3, il ne sera pas pris en compte. Par exemple : du gÃ©nÃ©ral de gaules, "du" et "de" nâ€™apparaÃ®tront pas dans l'index et donc ne seront pas pris en compte dans les matchs trigrams.  
:::

## Score avec tokenizer "n-grams"

Score pour chaque voie :
$$
score_{voie} = \sum_{\text{âˆ€ngram} \in \text{N}} {nb\_occurrence}_{ngram}
$$

N = ensemble des n-grams de l'adresse recherchÃ©e

## Limites des n-grams

$$
\downarrow \text{taille n-grams}
\Rightarrow \text{taille index inversÃ©} \uparrow 
\Rightarrow \text{temps de recherche} \uparrow
$$

- Limitation Ã  nâˆˆ{3,4,5} pour notre cas.  
- Tests effectuÃ©s pour choisir ces valeurs, en fonction de [**la prÃ©cision et la rapiditÃ©**]{.blue2} des requÃªtes.  

## Fuzziness

Contourner les fautes d'orthographes d'une autre faÃ§on : [**fuzziness**]{.green2}.  

<br>

Pour matcher ğŸ¯ deux mots avec une fuzziness de niveau 1 = corriger l'un des mots :

- Ajout d'une lettre.  
- Suppression d'une lettre.  
- Remplacement d'une lettre.  
- Ã‰changer deux lettres de place.  

## Score global 

Le score global va donc combiner la somme des matchs ğŸ¯ au niveau :

- mot.  
- n-grams.  
- fuzziness.  

## Boost

- On peut donner plus ou moins d'importance aux diffÃ©rents matchs ğŸ¯.  
- Chaque occurrence est multipliÃ©e par un facteur, appelÃ© [**boost**]{.blue2}, qui dÃ©pend du niveau de match ğŸ¯.  

## Retour sur le score global

$$
score_{voie} = \sum_{\text{âˆ€n} \in \text{N}} \sum_{\text{âˆ€sc} \in \text{n}} boost_{n}*{nb\_occurrence}_{sc}
$$

N = ensemble des niveaux *(niveau mot, niveau fuzzi...)*  
n = niveau  
sc = sous-chaÃ®ne *(un mot, un 3-grams...)*  

<!-- ## Configurer le moteur âš™ï¸

Une fois qu'on a la thÃ©orie, il faut l'appliquer en pratique.  

Le package elasticsearch permet d'indexer les donnÃ©es en fournissant :  

- Un dataframe ğŸ“‹ des donnÃ©es du rÃ©fÃ©rentiel GaÃ¯a.  
- Des [**settings**]{.blue2} ğŸ› ï¸ oÃ¹ on dÃ©finit nos diffÃ©rents **analyzers**, englobant les filtres et le motizer.  
- Des [**mappings**]{.green2} ğŸ·ï¸ oÃ¹ pour chaque **variable**, on fournit un analyzer.   -->

## Faire des recherches

Une recherche = une requÃªte ğŸ”.  

*RequÃªte pour retrouver la voie :*  

- Match ğŸ¯ nom de voie entier sans dÃ©coupage avec fuzzi 1 â†’ boost 200. *Ex : "3 rue du genral de gaulle" avec "du gen**e**ral de gaulle"*.  
- Match ğŸ¯ chaque mot du nom de voie avec fuzzi 1 â†’ boost 15. *Ex : "3 rue du genral de gaule" avec "du", "gen**e**ral", "de", "gaul**l**e"*.  
- Match ğŸ¯ chaque mot du type de voie avec fuzzi 1 â†’ boost 5. *Ex : "3 rue du general de gaule" avec "rue"*.  
- Match ğŸ¯ chaque 3 Ã  5-grams du nom de voie â†’ boost 1.  

Ã€ chaque fois qu'une sous-chaÃ®ne valide l'une de ces conditions, le score va â‡¡ en fonction du boost associÃ©.

::: {.notes}
- On match Ã  chaque 3-grams, exemple avec verdier.  
- Les ngrams c'est notre dernier recours, on va retourner comme voie plus pertinente les match sur nom de voie complet et sur token mais ngrams c'est notre roue de secours.
:::