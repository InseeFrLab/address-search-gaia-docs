## C'est quoi ElasticSearch ?

- [**ElasticSearch**]{.blue2} : logiciel pour l'indexation et la recherche de donnÃ©es.

- Utilisation en pratique avec [**Python**]{.green2} : packages *elasticsearch* et *elasticsearch-dsl*.


## Pourquoi ElasticSearch pour la recherche textuelle ?

| **CritÃ¨res**                         | **ElasticSearch** | **SQL** | **Addok**|
|:-------------------------------------|:-----------------:|:-------:|:-------:|
| Recherche de texte avancÃ©e           | âœ… | âŒ | âœ… |
| Personnalisation des recherches      | âœ… | âŒ | âŒ |
| RapiditÃ©                             | âœ… | âœ… | âœ… |
| PrÃ©cision                            | âœ… | âŒ | âš ï¸ |
| FacilitÃ© d'implÃ©mentation            | âŒ | âœ… | âœ… |
| Ressources                           | âŒ | âœ… | âœ… |
| Maintenance                          | âš ï¸ | âœ… | âŒ |

::: {.notes}
Donner explication addok
::: 

<!-- a refaire car je ne connais pas addok, j'ai pas compris -->

<!-- | **CritÃ¨res**                     | **Elasticsearch (Avantages)**                                                                                             | **SQL (InconvÃ©nients)**                                                                                       |
|----------------------------------|----------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------|
| **Recherche de texte avancÃ©e**   | ConÃ§u pour la recherche full-text avec tolÃ©rance aux fautes d'orthographe (fuzzy search, correspondance partielle)         | RequÃªtes full-text limitÃ©es et moins adaptÃ©es aux variations d'orthographe                                    |
| **Performances**                 | OptimisÃ© pour les recherches intensives sur de gros volumes de texte                                                       | Moins performant pour des recherches complexes ou de grandes quantitÃ©s de donnÃ©es textuelles                  |
| **Personnalisation des scores**  | Permet de pondÃ©rer et personnaliser les scores des rÃ©sultats pour une meilleure pertinence                                | Les options de personnalisation des scores sont limitÃ©es                                                      |
| **ScalabilitÃ©**                  | Distribution facile sur plusieurs nÅ“uds pour gÃ©rer de grands ensembles de donnÃ©es                                         | ScalabilitÃ© plus complexe et generalement moins performante pour des recherches intensives                    |
| **FlexibilitÃ© des requÃªtes**     | Recherches avancÃ©es comme les synonymes, phonÃ©tique, et suggestions automatiques                                          | RequÃªtes avancÃ©es limitÃ©es, difficile Ã  implÃ©menter en SQL                                                    |
| **ComplexitÃ© d'implÃ©mentation**  | Peut Ãªtre complexe Ã  mettre en Å“uvre pour des Ã©quipes non familiÃ¨res avec l'outil                                         | Plus simple et souvent mieux maÃ®trisÃ© par les Ã©quipes                                                        |
| **Consommation des ressources**  | Consomme plus de mÃ©moire et de CPU, en particulier pour l'indexation initiale                                             | Consommation de ressources generalement infÃ©rieure pour des requÃªtes simples                                  |
| **CoÃ»t de stockage**             | Peut impliquer une duplication des donnÃ©es (coÃ»t supplÃ©mentaire de stockage)                                              | Pas de duplication nÃ©cessaire                                                                                 | -->

## Outils pour moteur ElasticSearch

- [**Mappings**]{.blue2} ğŸ·ï¸ : spÃ©cifier les traitements Ã  appliquer pour chaque variable de nos donnÃ©es.  
  - *Variable_a â†’ Analyzer_for_numbers*  
  - *Variable_b â†’ Analyzer_for_address_text*  
  - *Variable_c â†’ Analyzer_for_address_text*  
- [**Settings**]{.blue2} ğŸ› ï¸ : dÃ©finir les diffÃ©rents traitements.  
  - *Analyzer_for_numbers â†’ Filtre_Î±, Filtre_Î² + Tokenizer_1*  
  - *Analyzer_for_address_text â†’ Filtre_Î³, Filtre_Î´, Filtre_Îµ + Tokenizer_2*  
- [**RequÃªtes**]{.blue2} ğŸ” : recherche sur les variables dÃ©finies dans les mappings.  

::: {.notes}
Et Ã©ventuellement, savoir coder en Python/Java...
::: 

On peut commencer Ã  crÃ©er notre moteur âš™ï¸.

# Ã‰tape 1 : pouvoir comparer l'adresse recherchÃ©e avec les donnÃ©es GaÃ¯a.

## Filtres

- DÃ©finis dans les *settings* ğŸ› ï¸.  
- Normalisent les donnÃ©es.  
- Pour les donnÃ©es du rÃ©fÃ©rentiel et pour les adresses recherchÃ©es.

## Filtres implÃ©mentÃ©s

- Lowercase  
- Asciifolding  
- Ponctuation  
- SÃ©paration des nombres et lettres *(ex : 14bis â†’ 14 bis)*  
- Suppression des espaces supplÃ©mentaires  
- [**Dillatation des accronymes/prise en compte des synonymes**]{.red2}  

# Ã‰tape 2 : dÃ©finir un score.

## Base de donnÃ©es classique

*Exemple*  

| idVoie | nom de voie             |
|---|:-----------------------------|
| A | du general leclerc           |
| B | du general charles de gaulle |
| C | du point du jour             |
| D | verdier                      |
| E | des cours                    |

## Recherche par token

- [**Un token = un mot.**]{.green2}  
- [**Pour chaque nom de voie du rÃ©fÃ©rentiel**]{.blue2}, compter le nombre de tokens qui matchent ğŸ¯ avec les tokens de l'adresse recherchÃ©e.

## Score avec tokenizer "token"

[**Pour retourner la voie la plus pertinente**]{.blue2}, on construit un score pour chaque voie :
$$
score_{voie} = \sum_{\text{âˆ€t} \in \text{T}} {nb\_occurrence}_t
$$

t = token  
T = ensemble des tokens de l'adresse recherchÃ©e  

## Score avec tokenizer "token"

*Exemple : score avec tokenizer "token" de "88 avenue du general charles de gaulle"*

| idVoie | nom de voie             | score |
|---|:-----------------------------|-------|
| A | **du general** leclerc           | 2     |
| B | **du general charles de gaulle** | 5     |
| C | **du** point **du** jour         | 2     |
| D | verdier                          | 0     |
| E | des cours                        | 0     |

[**Dans une grande base de donnÃ©es, c'est extrÃªmement long.**]{.red2}

# Ã‰tape 3 : utiliser un index inversÃ©. Mais qu'est ce donc ?

## Index inversÃ© token

*Exemple*  

<!-- | idVoie | nom de voie             |                        | token     | occurrences              |
|---|:-----------------------------|                        |-----------|--------------------------|
| A | du general leclerc           |                        | general   | {"A": 1, "B": 1}         |
| B | du general charles de gaulle |        devient         | jour      | {"C": 1}                 |
| C | du point du jour             |                        | du        | {"A": 1, "B": 1, "C": 2} |
| D | verdier                      |                        | ...       | ...                      |
| E | des cours                    | -->

<div style="display: flex; justify-content: space-between;">

<table>
  <thead>
    <tr>
      <th>idVoie</th>
      <th>nom de voie</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>A</td>
      <td>du general leclerc</td>
    </tr>
    <tr>
      <td>B</td>
      <td>du general charles de gaulle</td>
    </tr>
    <tr>
      <td>C</td>
      <td>du point du jour</td>
    </tr>
    <tr>
      <td>D</td>
      <td>verdier</td>
    </tr>
    <tr>
      <td>E</td>
      <td>des cours</td>
    </tr>
  </tbody>
</table>

<!-- Ajoutez un espacement entre les deux tableaux -->
<div style="margin-left: 130px;"></div>

<table>
  <thead>
    <tr>
      <th>token</th>
      <th>occurrences</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>general</td>
      <td>{"A": 1, "B": 1}</td>
    </tr>
    <tr>
      <td>jour</td>
      <td>{"C": 1}</td>
    </tr>
    <tr>
      <td>du</td>
      <td>{"A": 1, "B": 1, "C": 2}</td>
    </tr>
    <tr>
      <td>cours</td>
      <td>{"E": 1}</td>
    </tr>
    <tr>
      <td>...</td>
      <td>...</td>
    </tr>
  </tbody>
</table>
</div>

[**Comptage direct âš¡ des occurrences**]{.green2} de chaque token de la base par idVoie.

::: {.notes}
Faire un index inversÃ© par token, c'est rÃ©cupÃ©rer tous les tokens des noms de voie dans le rÃ©fÃ©rentiel et on les aplati dans une colonne.

Nous obtenons directement le comptage de chaque token par idVoie, pour tous les tokens prÃ©sents dans les noms de voie du rÃ©fÃ©rentiel.
::: 

# Ã‰tape 4 : prendre en compte les variations textuelles.

## Recherche par n-grams de caractÃ¨res

[**Contourner les fautes d'orthographes**]{.blue2} : chaque token est dÃ©coupÃ© en sous-chaÃ®nes de n caractÃ¨res consÃ©cutifs.  

*Exemple de dÃ©coupage en 3-grams de caractÃ¨res du texte "avenue verdier" :*  
**ave, ven, enu, nue, ver, erd, rdi, die, ier**

<!-- | token    | 3-grams                 |
|----------|-------------------------|
| avenue   | ave, ven, enu, nue      |
| verdier  | ver, erd, rdi, die, ier | -->


## Index inversÃ© 3-grams

*Exemple*  

<!-- | 3-grams | occurrences           |
|---------|-----------------------|
| gen     | {"A": 1, "B": 1}      |
| char    | {"B": 1}              |
| our     | {"C": 1, "E": 1}      |
| ...     | ...                   | -->



<div style="display: flex; justify-content: space-between;">

<table>
  <thead>
    <tr>
      <th>idVoie</th>
      <th>nom de voie</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>A</td>
      <td>du general leclerc</td>
    </tr>
    <tr>
      <td>B</td>
      <td>du general charles de gaulle</td>
    </tr>
    <tr>
      <td>C</td>
      <td>du point du jour</td>
    </tr>
    <tr>
      <td>D</td>
      <td>verdier</td>
    </tr>
    <tr>
      <td>E</td>
      <td>des cours</td>
    </tr>
  </tbody>
</table>

<!-- Ajoutez un espacement entre les deux tableaux -->
<div style="margin-left: 130px;"></div>

<table>
  <thead>
    <tr>
      <th>3-gram</th>
      <th>occurrences</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>gen</td>
      <td>{"A": 1, "B": 1}</td>
    </tr>
    <tr>
      <td>char</td>
      <td>{"B": 1}</td>
    </tr>
    <tr>
      <td>our</td>
      <td>{"C": 1, "E": 1}</td>
    </tr>
    <tr>
      <td>oin</td>
      <td>{"C": 1}</td>
    </tr>
    <tr>
      <td>...</td>
      <td>...</td>
    </tr>
  </tbody>
</table>
</div>

## Score avec tokenizer "n-grams"

Score pour chaque voie :
$$
score_{voie} = \sum_{\text{âˆ€ngram} \in \text{N}} {nb\_occurrence}_{ngram}
$$

N = ensemble des n-grams de l'adresse recherchÃ©e

## Limites des n-grams

$$
\downarrow \text{taille n-grams}
\Rightarrow \text{taille index inversÃ©} \uparrow 
\Rightarrow \text{temps de recherche} \uparrow
$$

Limitation Ã  minimum nâˆˆ{3,4,5} pour notre cas.

## Fuzziness

Contourner les fautes d'orthographes d'une autre faÃ§on : [**fuzziness**]{.green2}.  

<br>

Pour matcher ğŸ¯ deux tokens avec une fuzziness de niveau 1 = corriger l'un des tokens :

- Ajout d'une lettre.  
- Suppression d'une lettre.  
- Remplacement d'une lettre.  
- Ã‰changer deux lettres de place.  

## Score global 

Le score global va donc combiner la somme des matchs ğŸ¯ au niveau :

- token.  
- n-grams.  
- fuzziness.  

## Boost

On peut donner plus ou moins d'importance aux diffÃ©rents matchs ğŸ¯.  
Chaque occurrence est multipliÃ©e par un facteur, appelÃ© [**boost**]{.blue2}, qui dÃ©pend du niveau de match ğŸ¯.

## Boosts dans GaÃ¯a

| **match au niveau**| **boost** | **exemple** |
|----------|----|----------|
| token    | 20 | "verdier" avec "verdier" |
| fuzzi 1  | 15 | "verdier" avec "verdie" |
| 3-grams  | 1  | "ver" avec "ver" |
| 4-ngrams | 1  | "erdi" avec "erdi" |
| 5-grams  | 1  | "verdi" avec "verdi" |

*Exemple : recherche de "88 avenue verdier" et dans la base il y a la voie D : "verdier".*

## Retour sur le score global

$$
score_{voie} = \sum_{\text{âˆ€n} \in \text{N}} \sum_{\text{âˆ€sc} \in \text{n}} boost_{n}*{nb\_occurrence}_{sc}
$$

N = ensemble des niveaux *(niveau token, niveau fuzzi...)*  
n = niveau  
sc = sous-chaÃ®ne *(un token, un 3-grams...)*  

## Configurer le moteur âš™ï¸

Une fois qu'on a la thÃ©orie, il faut l'appliquer en pratique.  

Le package elasticsearch permet d'indexer les donnÃ©es en fournissant :  

- Un dataframe ğŸ“‹ des donnÃ©es du rÃ©fÃ©rentiel GaÃ¯a.  
- Des [**settings**]{.blue2} ğŸ› ï¸ oÃ¹ on dÃ©finit nos diffÃ©rents **analyzers**, englobant les filtres et le tokenizer.  
- Des [**mappings**]{.green2} ğŸ·ï¸ oÃ¹ pour chaque **variable**, on fournit un analyzer.  

## Faire des recherches

Une fois le moteur configurÃ©, on peut faire des requÃªtes ğŸ”.

*RequÃªte pour retrouver la voie :*

- Match ğŸ¯ token sur nom de voie avec fuzzi 1 â†’ boost 20.  
- Match ğŸ¯ token sur type de voie ou nom de voie â†’ boost 15.  
- Match ğŸ¯ 3 Ã  5-grams sur nom de voie â†’ boost 1.  

Ã€ chaque fois qu'une sous-chaÃ®ne valide l'une de ces conditions, le score va â‡¡ en fonction du boost associÃ©.